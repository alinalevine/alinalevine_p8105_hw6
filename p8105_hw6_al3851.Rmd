---
title: "HW 6"
author: "Alina Levine"
date: "November 19, 2018"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(ggplot2)
library(leaps)
library(modelr)
```

#Problem 1

##Clean Data

```{r clean data, results = "hide", warning = FALSE, message = FALSE}

homicide_df = read_csv("./Data/homicide-data.csv") %>%
  mutate(city_state = str_c(city, state, sep = ",")) %>%
  mutate(disposition = recode(disposition, 
                              `Closed without arrest` = "unsolved", 
                              `Open/No arrest` = "unsolved",
                              `Closed by arrest` = "solved")) %>%
  mutate(disposition = fct_relevel(disposition, "unsolved")) %>%
  mutate(disposition  = factor(disposition)) %>%
  filter(!(city_state %in% c("Dallas,TX", "Phoenix,AZ", "Kansas City,MO", "Tulsa,AL"))) %>%
  mutate(victim_race = ifelse(victim_race == "White", "white", "non-white")) %>%
  mutate(victim_race = factor(victim_race, levels = c("white", "non-white"))) %>%
  mutate(victim_age = as.numeric(victim_age)) %>%
  select(city_state, victim_sex, victim_race, victim_age,disposition)
  

```

Many cities are missing victim_age


##Baltimore Race Odds Ratio

I will fit a logistic model and then will use broom::tidy() and the confint function to get confidence intervals of the estimates. I will take the exponential of the race coefficient to get the ratio between the odds of cases for white people being solved and cases for non-white people being solved.

```{r baltimore, results = "hide", warning = FALSE, message = FALSE}
 baltimore_glm = homicide_df %>%
  filter(city_state == "Baltimore,MD") %>%
  glm(disposition ~ victim_sex + victim_race+victim_age , data = ., family = binomial())


est_CI_balt = baltimore_glm %>%
  broom::tidy(confint(.)) %>%
  filter(term == "victim_racenon-white") %>%
  select(estimate, conf.low,conf.high) %>%
  mutate(estimate = exp(estimate),
         conf.low = exp(conf.low),
         conf.high = exp(conf.high))


```

A non-white person who is killed has `r est_CI_balt$estimate` times the odds of the homicide case being solved than a white person has.

##Every City Race Odds Ratio

First I am nesting by city_state and then am creating a list column by mapping confint(the model) onto each city state to get the confidence interval for each city. Then I am creating another list column by mapping mapping broom::tidy(the model), so I can extract coefficient estimates. After I unnest, I can take the exponetial of the the confidence intervals and coefficients to get the odds ratio estimate and confidence interval for each city. 

```{r all city odds ratio, warning = FALSE, message = FALSE, results = "hide"}

all_city_estimates = homicide_df %>%
  group_by(city_state) %>%
  nest() %>%
  mutate(confint = map(data,~confint(glm(disposition ~ victim_sex + 
                                           victim_age + 
                                           victim_race, 
                                           data = .x, family = binomial()))),
          confint = map(confint, broom::tidy),
          regression = map(data, ~glm(disposition ~ victim_sex + 
                                            victim_age + 
                                            victim_race, 
                                            data = .x, 
                                            family = binomial())),
          regression = map(regression, broom::tidy)) %>%
  select(city_state, regression, confint) %>%
  unnest() %>%
  select(city_state,term, estimate,X2.5..,X97.5..) %>%
  filter(term == "victim_racenon-white") %>%
  mutate(estimate = exp(estimate),
         X2.5.. = exp(X2.5..),
         X97.5.. = exp(X97.5..)) %>%
  rename(conf_low = X2.5..,
         conf_high = X97.5..) %>%
  select(-term)

all_city_estimates %>%
  mutate(city_state = fct_reorder(city_state, estimate)) %>%
  ggplot(aes( x = city_state, y = estimate )) +
    geom_errorbar(aes(ymin = conf_low, ymax = conf_high), width = .1) +
    geom_point() +
    theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
    labs(title = "Solved Homicides Odds Ratio: nonwhite:white",
         x = "city",
         y = "odds ratio")

```

#Problem 2


##Data Cleaning

ppbmi is very highly correlated with weight, so I am removing this variable. ppwt is very highly correlated with delivery weight, so I am also removing that. Additionally, there is only 1 value for pnumlbw and pnumsga, so I am removing those. I am also looking at the correlation between numeric variables to remove redundant variables.

```{r data cleaning, results = "hide", message = FALSE, warning = FALSE}

birthweight_df = read_csv("./Data/birthweight.csv") %>%
  mutate(babysex = factor(babysex),
         frace = factor(frace),
         malform = factor(malform),
         mrace = factor(mrace),
         )  

birthweight_df %>%
  skimr::skim()

birthweight_df %>%
  select_if(is.numeric) %>%
  cor

birthweight_df = birthweight_df %>%
  select(-c(pnumlbw, pnumsga, ppbmi, ppwt))

#no missing data

```

##Choosing Model

I am using the model with the lowest BIC to choose my model. I am plotting the combination of variables that produces the lowest BIC for each number of predictors.

```{r BIC criteria, results = "hide", message = FALSE, warning = FALSE}

leaps_birthweight = regsubsets(bwt~., data = birthweight_df, nbest = 1, nvmax = 16)
plot(leaps_birthweight)

```

This plot shows that the model with the lowest bic includes sex of the baby, head circumference, length of baby, mother's weight at delivery, father's race, mother's race, gestational weeks, mother's height, parity, number of cigarettes, and weightgain. 

##Fitting the model

```{r fit my model, results = "hide", warning = FALSE, message = FALSE}
fit_birthweight = lm(bwt~babysex + bhead + blength + 
                       delwt + frace + mrace + 
                       gaweeks + mheight + wtgain + 
                       smoken, 
                       data = birthweight_df)
```




##Residuals Vs. Fitted Values

```{r residuals versus fitted value plots, results = "hide", message = FALSE, warning = FALSE}

birthweight_pred = add_predictions(birthweight_df, fit_birthweight)
birthweight_pred_res = add_residuals(birthweight_pred, fit_birthweight)

birthweight_df %>% 
  modelr::add_residuals(fit_birthweight) %>% 
  modelr::add_predictions(fit_birthweight) %>%
  ggplot(aes(x = pred, y = resid)) +
    geom_point()



```

This does not look like a great model because the error variance is not constant over the predicted values. The error gets very high as predicted values get to the lower extremes. However, I looked at the plots of subsets of the variables I chose, and a similar phenomena happened for these subsets as well. 

##Comparison Models

```{r comparison models, results = "hide", message = FALSE, warning = FALSE}

fit_simple = lm(bwt ~ blength + gaweeks, data = birthweight_df)
fit_interactions = lm(bwt~ (bhead + blength + babysex)^3, data = birthweight_df)


```

##Cross Validation comparisons 

```{r cross validation, results = "hide", message = FALSE, warning = FALSE}

cv_birthweight = 
  crossv_mc(birthweight_df, n = 100) %>%
  mutate(train = map(train, as_tibble),
         test = map(test, as_tibble)) %>%
  mutate(my_mod = map(train, ~lm(bwt ~ babysex + bhead + blength + 
                                   delwt + frace + mrace + gaweeks + 
                                   mheight + wtgain + smoken, data = .x)),
         simple_mod = map(train, ~lm(bwt ~ blength + gaweeks, data = .x)),
         interactions_mod = map(train, ~lm(bwt~ (bhead + blength + babysex)^3, data = .x))) %>% 
  mutate(rmse_my_mod  = map2_dbl(my_mod, test, ~rmse(model = .x, data = .y)),
         rmse_simple_mod = map2_dbl(simple_mod, test, ~rmse(model = .x, data = .y)),
         rmse_interactions_mod = map2_dbl(interactions_mod, test, ~rmse(model = .x, data = .y)))
```

##RMSE Comparisons

```{r compare rmse, results = "hide", warning = FALSE, message = FALSE}

cv_birthweight %>%
  select(rmse_my_mod, rmse_simple_mod, rmse_interactions_mod) %>%
  unnest() %>%
  gather(key = "model", value = "rmse") %>%
  mutate(model = str_replace(model, "rmse_", "")) %>%
  ggplot(aes( x = model, y = rmse)) +
    geom_boxplot() +
    labs(title = "RMSE Comparison")


```

The box plots that plot the rmse for each split of the dataset show that my model performs better than the the model that uses cicumference, length, sex and all interactions and the model that uses length at birth and gestational age, as the distribution of rmse values is lower. The worst performing model is the model only using length at birth and gestational age because its disribution of rmse values is highest.  
